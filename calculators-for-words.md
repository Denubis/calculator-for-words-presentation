---
title: "Is the `Calculator for Words' metaphor useful for communicating about LLMs?"
author: 
    - "Dr Brian Ballsun-Stanton"
    - "Dr InÃªs Hipolito"
bibliography: references.bib
---

## This is not a new problem

> Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?

[@babbage_passages_1864]


## Motivation

- Why are we here?
- Why is the metaphor a problem?
- Why continue this discussion?


## Aim

How do we communicate the affordances of these tools to people we are teaching, communicating with, and writing policy for in such a way that they avoid error-prone patterns of use?

## The problem

* We have too many stories about "AI"
* They respond using "I"
* People see the tools through skeuomorphic lenses, rather than understanding the limitations and capabilities of the technologies themselves.



# For 'Calculators for words'

## Willison on how to think about LLMs

> One of the most pervasive mistakes I see people using with large language model tools like ChatGPT is trying to use them as a search engine. ... I like to think of language models like ChatGPT as a calculator for words. ... Want them to work with specific facts? Paste those into the language model as part of your original prompt! [@willison_think_2023]


## Unreliability

This quote moves the locus of control to the user's perspective:

* Their input is primary, isntead of the 'creative' output of the machine
* A specific method of grounding inputs to reduce confabulation
* Mapping to prior affordances that users are expecting

## ???

TODO


# Against 'Calculators for words'


## Bucci's response

> To put it differently, a calculator has a well-defined, well-scoped set of use cases, a well-defined, well-scoped user interface, and a set of well-understood and expected behaviors that occur in response to manipulations of that interface. ... Large language models, when used to drive chatbots or similar interactive text-generation systems, have none of those qualities. They have an open-ended set of unspecified use cases.

[@bucci_word_2023]

## Far too literal 


* We agree that the opacity of the function of a neural net is deeply problematic, for all sorts of reasons. 
* But that these things, qua tools, represent an instance of an exocortex that is in direct continuation of the line of computing machines from those which work by pure analogy to those which are online.

## More skeuomorphic literalism

* Calcualtors are not AI. 

## Actual issue



# Discussion

## The pragmatics of experience

> When I speak in front of groups and ask them to raise their hands if they used the free version of ChatGPT, almost every hand goes up. When I ask the same group how many use GPT-4, almost no one raises their hand. I increasingly think the decision of OpenAI to make the ``bad'' AI free is causing people to miss why AI seems like such a huge deal to a minority of people that use advanced systems and elicits a shrug from everyone else. [@mollick_opinionated_2023]

## Haraway's Cyborgs

## Epistimology engines




## Bibilography